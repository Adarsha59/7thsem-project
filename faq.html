"use client";

import { useEffect, useRef } from "react";
import * as faceapi from "face-api.js";

const FaceDetection = () => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const animationRef = useRef(null);

  const challengeExpressions = ["happy", "sad", "surprised", "neutral"];
  const currentChallengeIndexRef = useRef(0);
  const challengeResultsRef = useRef([]);
  const challengeIssuedTimeRef = useRef(null);
  const expectedExpressionsRef = useRef([]);
  const resultDeclaredRef = useRef(false);

  useEffect(() => {
    let stream;

    const loadModels = async () => {
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
          faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
          faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
          faceapi.nets.faceExpressionNet.loadFromUri("/models"),
        ]);
        await startVideo();
      } catch (err) {
        console.error("Model loading failed:", err);
      }
    };

    const startVideo = async () => {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
      } catch (err) {
        console.error("Error accessing webcam:", err);
      }
    };

    loadModels();

    return () => {
      if (stream) {
        stream.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  useEffect(() => {
    const getTwoUniqueExpressions = () => {
      const shuffled = [...challengeExpressions].sort(
        () => 0.5 - Math.random()
      );
      return [shuffled[0], shuffled[1]];
    };

    const issueNextChallenge = () => {
      const currentIndex = currentChallengeIndexRef.current;
      const nextExpr = expectedExpressionsRef.current[currentIndex];
      challengeIssuedTimeRef.current = Date.now();
      alert(`Please show '${nextExpr}' expression`);
    };

    const handleVideoPlay = () => {
      const video = videoRef.current;
      const canvas = canvasRef.current;

      if (!video || !canvas) return;

      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);

      expectedExpressionsRef.current = getTwoUniqueExpressions();
      currentChallengeIndexRef.current = 0;
      challengeResultsRef.current = [];
      resultDeclaredRef.current = false;
      issueNextChallenge();

      const render = async () => {
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceExpressions();

        const resizedDetections = faceapi.resizeResults(
          detections,
          displaySize
        );
        const ctx = canvas.getContext("2d");

        if (ctx) {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resizedDetections);
          faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
          faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
        }

        const now = Date.now();
        const timePassed = now - challengeIssuedTimeRef.current;

        if (
          resizedDetections.length > 0 &&
          currentChallengeIndexRef.current < 2 &&
          timePassed > 5000
        ) {
          const expressions = resizedDetections[0].expressions;
          const expected =
            expectedExpressionsRef.current[currentChallengeIndexRef.current];
          const confidence = expressions[expected] || 0;
          const passed = confidence > 0.6;

          challengeResultsRef.current.push(passed);
          currentChallengeIndexRef.current++;

          if (currentChallengeIndexRef.current < 2) {
            issueNextChallenge();
          } else {
            // Final result after 2 challenges
            setTimeout(() => {
              if (!resultDeclaredRef.current) {
                if (challengeResultsRef.current.every((r) => r)) {
                  alert("Hi user ðŸ‘‹");
                } else {
                  alert("Hey robot ðŸ¤–");
                }
                resultDeclaredRef.current = true;

                // Restart after 3 seconds
                setTimeout(() => {
                  expectedExpressionsRef.current = getTwoUniqueExpressions();
                  currentChallengeIndexRef.current = 0;
                  challengeResultsRef.current = [];
                  resultDeclaredRef.current = false;
                  issueNextChallenge();
                }, 3000);
              }
            }, 500); // brief pause before declaring
          }
        }

        animationRef.current = requestAnimationFrame(render);
      };

      render();
    };

    const video = videoRef.current;
    if (video) {
      video.addEventListener("play", handleVideoPlay);
    }

    return () => {
      if (video) {
        video.removeEventListener("play", handleVideoPlay);
      }
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, []);

  return (
    <div
      style={{
        position: "relative",
        display: "flex",
        justifyContent: "center",
        alignItems: "center",
        height: "100vh",
      }}
    >
      <video
        ref={videoRef}
        width="720"
        height="560"
        autoPlay
        muted
        playsInline
        style={{ position: "absolute" }}
      />
      <canvas
        ref={canvasRef}
        width="720"
        height="560"
        style={{ position: "absolute" }}
      />
    </div>
  );
};

export default FaceDetection;
